---
title: "Data Science em Gestão de Negócios e Finanças"
subtitle: "<br>Introdução ao Tidyverse 1"  
author: "Arthur Welle"
date: "`r gsub(' 0', ' ', format(Sys.Date(), format='%d %b, %Y'))`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["custom.css"] 
    nature:
      highlightStyle: tomorrow-night-bright
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: ["center","top"]
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
library(gapminder)
```

# Índice

1. Dividindo e selecionado dados

2. Criando Variáveis

3. Agregando dados

4. Tidying dados

5. Juntando diferentes bases de dados

6. Material adicional

---
class: inverse

# O que será necessário hoje

---
# Pacotes

Esta apresentação está baseada inteiramente nos pacotes do [`tidyverse`](https://www.tidyverse.org/).

--

O `tidyverse` é uma coleção de pacotes de R que compatilham o mesmo design, a mesma sintaxe, e a mesma estrutura.

--

No `tidyverse` se incluem os pacotes mais utilizados no mundo do R: [`dplyr`](https://dplyr.tidyverse.org/) para manipular os dados e [`ggplot2`](https://ggplot2.tidyverse.org/) para visualizar os resultados.

--

Você pode instalar *todos* os pacotes do `tidyverse` de uma vez usando o seguinte comando:

```{r, eval=FALSE}
install.packages("tidyverse")
```

--

Usaremos também os pacotes `gapminder` e `nycflights13` que são pacotes contendo dados para alguns de nossos exercícios:

```{r, eval=FALSE}
install.packages("gapminder")
install.packages("nycflights13")
```

---
# gapminder

Inspecionar o banco de dados gapminder. Quais são suas variáveis?

`head(gapminder)` mostra as primeiras linhas

`colnames(gapminder)` mostra o nome das colunas do objeto gapminder

`glimpse(gapminder)` outra maneira de nos dar uma amostra das variáveis presentes no objeto

`view(gapminder)` abre o banco de dados para inspeção (cuidado ao fazer isso com grandes bancos de dados)


```{r}
glimpse(gapminder)
```

---
class: inverse

# Pipes `%>%`


---
# Pipes `%>%` 

O `Tidyverse` (e muitos outros pacotes) usam o operador **pipe** (**`%>%`**) advindo do pacote  [`magrittr`](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html). 

--

Desde maio de 2021 na versão [`4.1.0`](https://cran.r-project.org/bin/windows/base/NEWS.R-4.1.0.html ) do R  pipe foi implementado no R base, com na forma `|>`, mas como ele tem diferenças para o anterior vamos, por enquanto, preferir `%>%`.

--

O atalho para o `%>%` é `Ctrl+Shift+M` ou `⌘ +Shift+M` no Mac.

--

Pipes pegam os objetos a *esquerda* e aplicam è eles uma função à *direita*: `x %>% f() `. Lê-se "pegue x e então aplique a função f() neste objeto". A tradução lógica para pipe seria "e então..." 

---
# Pipes `%>%`

Os pipes nos ajudam a fazer o código ser mais legível pois seguem a sequência de passos que intuitivamente esperamos usar para transformar os dados.

--

Com o pipe você pode reescrever isso:

```{r, eval=FALSE}
corta(assa(mistura(compra(lista_ingredientes))))
```

desta maneira:

```{r, eval=FALSE}
lista_ingredientes %>% 
    compra() %>% 
    mistura() %>% 
    assa() %>% 
    corta()
```

São logicamente equivalentes mas com o pipe a ordem de leitura segue a ordem cognitiva.
---

Exemplo abaixo:

  1) crie objeto com 100 números aleatórios **e então...**
  
  2) cria a densidade de probabilidade **e então...**
  
  3) plota no gráfico o resultado.
  
```{r, fig.height=5, fig.width=8}
rnorm(100) %>% 
  density() %>% 
  plot() 
```


---
Outro exemplo:

  1) Pegue objeto "gapminder", **e então...**
  
  2) Selecione somente o Canadá, **e então...**
  
  3) Mostre os dois primeiros casos.

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(gapminder)

gapminder %>% 
  filter(country == "Canada") %>%  
  head(2)
```

---

# Criando um objeto com o pipe

Quando queremos criar um novo objeto com o resultado de uma corrente de pipes podemos usar o operador `<-` no início da corrente, ou `->` no fim da corrente. Abaixo duas formas de criar o objeto chamado **"fatia"** com o resultado da cadeia de ações ou funções.

```{r, eval=FALSE}
fatia <- lista_ingredientes %>% 
    compra() %>% 
    mistura() %>% 
    assa() %>% 
    corta()
```

ou

```{r, eval=FALSE}
lista_ingredientes %>% 
    compra() %>% 
    mistura() %>% 
    assa() %>% 
    corta() -> fatia
```

---

# Usando Pipes

O resultado da função aplicada é passada para o *primeiro argumento* da função que vem a seguir. 

--

Caso hava necessidade de passar o resultado do fluxo de pipes para outro argumento que não o primeio basta usar o `.` que serve como marcador para o resultado anterior. Podemos fazer isso também se nomearmos os argumentos que a função usa.

```{r, eval=FALSE}
fatia <- lista_ingredientes %>% 
    compra(onde = "supermercado", oque = .) %>% 
    mistura(ferramenta = "colher", conteudo = .) %>% 
    assa(onde = "forno", oque = ., temperatura = 90) %>% 
    corta(tamanho = 2, oque = .)
```

.footnote[Note que o novo pipe nativo `|>` ainda não utiliza o marcador `.`.]

---
# Pipes `%>%`

Pipes são ótimos para tornar o código claro e legível. 

--

No entanto, ele não é recomendado uso quando o fluxo de passos não é linear, ou quando estamos gerando multiplos objetos.

---
class: inverse

# Manipulação de dados 

---

# Os quatro principais "verbos" do dplyr:

### `filter()` 

### `select()` 

### `mutate()`

### `summarize()`

uma "preposição":

### `group_by()`

.smaller[ e outros verbos como `arrange()`, `rename()`]
---

# `filter` Data Frames

**`filter()`** é usado para selecionar um conjunto de **linhas** dentro do banco de dados que satisfazem as condições lógicas dentro da função `filter()`.

```{r}
gapminder %>% 
  filter(country == "Oman") %>% 
  head(8)
```

O que isto está fazendo?

---

# Revisão de operadores lógicos

Operadores lógicos retornam *verdadeiro* (`TRUE`), *falso* (`FALSE`), ou *não disponível* `NA`.

--

`filter()` retorna os valores que atendem a condição, portanto verdadeiros (`TRUE`).

Usamos `==` para testes de igualdade: `country == "Oman"`.

--

Outros [operadores lógicos](http://www.statmethods.net/management/operators.html):

--

* `!=`: não igual a
--

* `>`, `>=`, `<`, `<=`: menor que, menor ou igual que, maior que, maior ou igual
--

* `%in%`: checa se é igual a pelo menos um elemento de um conjunto

--

Operadores usados para combinar outros 

* `&`: ambas as condições tem que ser verdadeiras (**E**)
--

* `|`: pelo menos uma das condições tem que ser verdadeira (**OU**)
--

* `!`: negação; inverte o valor do elemento (`TRUE` se torna `FALSE`, `FALSE` se torna `TRUE`)

---

# Exemplo de multiplas condições

Vamos filtrar a base para manter somente Oman entre 1980 e 2000.

--

```{r}
gapminder %>%
    filter(country == "Oman" &
           year > 1980 &
           year <= 2000 )
```

---
# `%in%` exemplo de uso

Filtrar linhas que tenham algo em comum com qualquer elemento de um conjunto de elementos.

```{r}
# criando objeto lista de membros fundadores do Mercosul
lista_paises_Mercosul <- c(
            "Brazil", 
            "Argentina",
            "Paraguai",
            "Uruguay") 

# cria nova base com países que estão na lista acima
mercosul <- gapminder %>%
  filter(country %in% lista_paises_Mercosul)

# mostra resultado
mercosul
```


---
## Ordenando: `arrange()`

podemo ordenar os resultados usando `arrange()`

```{r}
mercosul %>% 
  arrange(year, -pop)
```

Ordenados ascendentemente por `year` e descendentemente por `pop`.

---
## Selecionando colunas: `select()`

Além de filtrar linhas podemo selecionar as colunas de interesse usando **`select()`**. 

```{r}
mercosul %>% 
  select(country, year, pop) %>% 
  head(4)
```

Note que a ordem das colunas também mudou, seguindo a ordem passada para `select()`.
---
## Removendo colunas: `select()`


Podemos remover as colunas de interesse usando o sinal de menos (`-`) dentro do `select()`. 

```{r}
mercosul %>% 
  select(-continent, -pop, -lifeExp) %>% 
  head(4)
```

---
## Funções auxiliares para `select()`


`select()` tem um conjunto de funções auxiliares `starts_with()`, `ends_with()`, e `contains()`, ou ainda podemo usar um intervalo entre duas variáveis/colunas escolhidas `coluna1:coluna4`. Veja detalhes na ajuda da função usando `?select`.

Estas funções auxiliares são particularmente interessantes quando temos um banco de dados com muitas variáveis, ou variáveis com nomes parecidos. 


```{r}
mercosul %>%  
  select(starts_with("gdp")) %>% 
  head(4)
```

---
## Renomeando colunas com `select()`


Podemos renomear as coluans usando `select()`, mas lembre-se que toda colunas não mencionado será removida.

```{r}
mercosul %>%
    select(Life_Expectancy = lifeExp) %>%
    head(4)
```

---
### Renomeando colunas com `rename()`


**`rename()`** renomeia colunas com a mesma sintaxe que `select()` sem remover colunas não mencionadas.

```{r}
mercosul %>%
    select(country, year, lifeExp) %>%
    rename(Life_Expectancy = lifeExp) %>%
    head(4)
```

---
class: inverse
# Criando variáveis

---
## `mutate()`

No `dplyr`, você pode criar novas colunas/variáveis usando a função **`mutate()`**.


```{r}
mercosul %>% filter(country == "Brazil") %>%
    select(-continent, -lifeExp) %>%
    mutate(pop_million = pop / 1000000,
           GDP = gdpPercap * pop) %>% 
    head(5)
```

.footnote[Veja que podemos criar mais de uma variável no mesmo `mutate()` separando cada uma por uma vírgula.]

---
# `ifelse()`


Uma função comum usada dentro do`mutate()` é o **`ifelse()`**. Ele retorna um vetor de resultados baseado no resultado de um teste.

```{r, eval=TRUE}
x <- 1
y <- 2
ifelse(test = x==y, yes = "Verdadeiro" , no = "Falso")
```

Como em boa parte das funções se você entregar um vetor de valores ao `ifelse()` ele retorna também um vetor de resultados.  
--

Exemplo:

```{r}
vetor_valores <- c(1, 0, NA, -2)
ifelse(vetor_valores > 0, "Positivo", "Negativo")
```

Veja que o teste para `NA` retorna `NA`.

---
# `ifelse()` 


```{r}
mercosul %>% 
  mutate(apelido = ifelse(country == "Argentina",     # teste
                          "Hermanos",                 # se verdadeiro
                          as.character(country))) %>% # se falso
  select(country, apelido, year, pop) %>%
  arrange(year, apelido) %>%
  head(3)
```

Em português leia-se "para cada linha, se o país é igual à "Argentina" então faça a nova variável `apelido` ganhar o texto "**Hermanos**", caso contrário o valor da variável `country`. É uma maneira fácil de mudar alguns valores e não outros.

---
# `case_when()`

**`case_when()`** faz multiplas operações `ifelse()` ao mesmo tempo. `case_when()` permite criar uma nova variável baseado em critérios de outras variáveis.
.smallish[
```{r}
mercosul %>% 
  mutate(PIB_ranking = 
    case_when(
      gdpPercap <  5000 ~ "baixo",
      gdpPercap >= 5000 & gdpPercap < 7000 ~ "medio",
      TRUE ~ "alto" )) %>% # se todos os outros casos forem falso
  head(4)
```
]

---
class: inverse

# Sumarizando dados

---
## Agregando dados com `summarize()`

**`summarize()`** recebe uma ou mais colunas dos seus dados e computa algo usando todas as linhas exemplos: 

* contar quantas linhas tem o banco de dados
* calcular a média 
* Computar a soma total dos valores de uma coluna
* Obter mínimo ou máximo valor

Você pode usar qualquer função dentro de `summarize()` que transforme **multiplos valores** em um **único valor** (como `sd()`, `mean()`, ou `max()`).


---
# `summarize()` exemplo

Para o ano de 2010, vamos calcular o *número de observações*, *população total*, *média expectativa de vida*, and *intervalo da expectativa de vida* dos países do Mercosul.

```{r}
mercosul %>%
    filter(year == 2007) %>%
    summarize(n_obs = n(),
              total_pop = sum(pop),
              med_exp_vida = mean(lifeExp),
              intervalo_exp_vida = max(lifeExp) - min(lifeExp))
```

As novas variáveis criadas como resultado usaram *todas as linhas* dos dados de `mercosul`.

---
# `group_by()`


The special function **`group_by()`** changes how subsequent functions operate on the data, most importantly `summarize()`.

Functions after `group_by()` are computed *within each group* as defined by unique valus of the variables given, rather than over all rows at once.

Typically the variables you group by will be integers, factors, or characters, and *not continuous real values*.

---
`group_by()` example


```{r}
mercosul %>%
  group_by(year) %>% #<<
    summarize(num_countries = n_distinct(country),
              total_pop = sum(pop),
              total_gdp_per_cap = sum(pop*gdpPercap)/total_pop) %>%
    head(5)
```

Because we did `group_by()` with `year` then used `summarize()`, we get *one row per value of `year`*!

Each value of year is its own **group**!

---
## Window Functions

Grouping can also be used with `mutate()` or `filter()` to give rank orders within a group, lagged values, and cumulative sums. You can read more about window functions in this [vignette](https://cran.r-project.org/web/packages/dplyr/vignettes/window-functions.html).

```{r}
mercosul %>% 
  select(country, year, pop) %>%
  filter(year >= 2002) %>% 
  group_by(country) %>%
  mutate(lag_pop = lag(pop, order_by = year),
         pop_chg = pop - lag_pop) %>%
  head(4)
```


---
class: inverse
# Tidying Data

---
# Initial Spot Checks

.smallish[
First things to check after loading new data:
]
--

.smallish[
* Did the last rows/columns from the original file make it in?

    + May need to use different package or manually specify range
]
--

.smallish[
* Are the column names in good shape?

    + Modify a `col_names=` argument or fix with `rename()`
]
--
.smallish[

* Are there "decorative" blank rows or columns to remove?

    + `filter()` or `select()` out those rows/columns
]
--
.smallish[

* How are missing values represented: `NA`, `" "` (blank), `.` (period), `999`?

    + Use `mutate()` with `ifelse()` to fix these (perhaps *en masse* with looping)
]
--
.smallish[

* Are there character data (e.g. ZIP codes with leading zeroes) being incorrectly represented as numeric or vice versa?

    + Modify `col_types=` argument, or use `mutate()` and `as.numeric()`
]

---
# Slightly Messy Data

| **Program**     | **Female** | **Male** |
|-----------------|-----------:|---------:|
| Evans School    |     10     |    6    |
| Arts & Sciences |      5     |    6    |
| Public Health   |      2     |    3    |
| Other           |      5     |    1    |

--

* What is an observation?
    + A group of students from a program of a given gender
* What are the variables?
    + Program, Gender, Count
* What are the values?
    + Program: Evans School, Arts & Sciences, Public Health, Other
    + Gender: Female, Male -- **in the column headings, not its own column!**
    + Count: **spread over two columns!**

---
# Tidy Version

| **Program**     | **Gender** | **Count** |
|-----------------|-----------:|---------:|
| Evans School    |     Female |    10   |
| Evans School    |     Male   |    6    |
| Arts & Sciences |     Female |    5    |
| Arts & Sciences |     Male   |    6    |
| Public Health   |     Female |    2    |
| Public Health   |     Male   |    3    |
| Other           |     Female |    5    |
| Other           |     Male   |    1    |

Each variable is a column.

Each observation is a row.

Ready to throw into `ggplot()` or a model!


Data comes in many formats but R prefers just one: _tidy data_.

A data set is tidy if and only if:

1. Every variable is in its own column
2. Every observation is in its own row
3. Every value is in its own cell (which follows from the above)

What is a variable and an observation may depend on your immediate goal.



---
# Billboard Data

We're going to work with some *ugly* data: *The Billboard Hot 100 for the year 2000*.

We can load it like so:

```{r, warning=FALSE, message=FALSE}
library(readr) # Contains read_csv()
billboard_2000_raw <- 
  read_csv(file = "https://github.com/clanfear/Intermediate_R_Workshop/raw/master/data/billboard.csv",
           col_types = paste(c("icccD", rep("i", 76)), collapse="")) #<<
```

.footnote[`col_types=` is used to specify column types. [See here for details.](https://clanfear.github.io/CSSS508/Lectures/Week5/CSSS508_week5_data_import_export_cleaning.html#29)]

---
# Billboard is Just Ugly-Messy

.small[
```{r, echo=FALSE}
library(pander)
pander(head(billboard_2000_raw[,1:10], 12), split.tables=120, style="rmarkdown")
```
]

Week columns continue up to `wk76`!

---
# Billboard

* What are the **observations** in the data?

--

    + Week since entering the Billboard Hot 100 per song
--

* What are the **variables** in the data?
--

    + Year, artist, track, song length, date entered Hot 100, week since first entered Hot 100 (**spread over many columns**), rank during week (**spread over many columns**)
--

* What are the **values** in the data?
--

    + e.g. 2000; 3 Doors Down; Kryptonite; 3 minutes 53 seconds; April 8, 2000; Week 3 (**stuck in column headings**); rank 68 (**spread over many columns**)

---
# Tidy Data

**Tidy data** (aka "long data") are such that:

--

1. The values for a single observation are in their own row.
--

2. The values for a single variable are in their own column.
--

3. The observations are all of the same nature.

--

Why do we want tidy data?

* Easier to understand many rows than many columns
* Required for plotting in `ggplot2`
* Required for many types of statistical procedures (e.g. hierarchical or mixed effects models)
* Fewer confusing variable names
* Fewer issues with missing values and "imbalanced" repeated measures data

---
# `tidyr`

The `tidyr` package provides functions to tidy up data, similar to `reshape` in Stata or `varstocases` in SPSS. Key functions:

--

* **`gather()`**: takes a set of columns and rotates them down to make two new columns (which you can name yourself): 
    * A `key` that stores the original column names
    * A `value` with the values in those original columns

--

* **`spread()`**: inverts `gather()` by taking two columns and rotating them up into multiple columns

--

* **`separate()`**: pulls apart one column into multiple columns (common with `gather`ed data where values had been embedded in column names)
    * `extract_numeric()` does a simple version of this for the common case when you just want grab the number part

--

* **`extract()`** for spreading a column into multiple *sets* of columns.
   * See [Hadley's response to this question](https://stackoverflow.com/questions/25925556/gather-multiple-sets-of-columns) for an example.

---
# `gather()`

Let's use `gather()` to get the week and rank variables out of their current layout into two columns (big increase in rows, big drop in columns):

```{r, message=FALSE, warning=FALSE}
library(tidyr)
billboard_2000 <- billboard_2000_raw %>%
    gather(key = week, value = rank, starts_with("wk")) #<<
dim(billboard_2000)
```

`starts_with()` and other helper functions from `dplyr::select()` work here too.

We could instead use: `gather(key = week, value = rank, wk1:wk76)` to pull out these contiguous columns.

---
# `gather`ed Weeks

.smallish[
```{r, message=FALSE, warning=FALSE}
head(billboard_2000)
```
]

Now we have a single week column!

---
# Gathering Better?

```{r}
summary(billboard_2000$rank)
```

This is an improvement, but we don't want to keep the `r sum(is.na(billboard_2000$rank))` rows with missing ranks (i.e. observations for weeks since entering the Hot 100 that the song was no longer on the Hot 100).

---
# Gathering Better: `na.rm`

The argument `na.rm = TRUE` to `gather()` will remove rows with missing ranks.
```{r}
billboard_2000 <- billboard_2000_raw %>%
    gather(key = week, value = rank, starts_with("wk"),
           na.rm = TRUE) #<<
summary(billboard_2000$rank)
```

---
# `separate()`

The track length column isn't analytically friendly. Let's convert it to a number rather than the character (minutes:seconds) format:

```{r}
billboard_2000 <- billboard_2000 %>%
    separate(time, into = c("minutes", "seconds"),
             sep = ":", convert = TRUE) %>% #<<
    mutate(length = minutes + seconds / 60) %>%
    select(-minutes, -seconds)
summary(billboard_2000$length)
```

`sep = :` tells `separate()` to split the column into two where it finds a colon (`:`).

Then we add `seconds / 60` to `minutes` to produce a numeric `length` in minutes.

---
# `parse_number()`

`tidyr` provides a convenience function to grab just the numeric information from a column that mixes text and numbers:

```{r}
billboard_2000 <- billboard_2000 %>%
    mutate(week = parse_number(week)) #<<
summary(billboard_2000$week)
```

For more sophisticated conversion or pattern checking, you'll need to use string parsing (to be covered in week 8).

---
# `spread()` Motivation

`spread()` is the opposite of `gather()`, which you use if you have data for the same observation taking up multiple rows.

--

Example of data that we probably want to spread (unless we want to plot each statistic in its own facet):

.small[
| **Group** | **Statistic** | **Value** |
|-------|-----------|------:|
| A     | Mean      |  1.28 |
| A     | Median    |   1.0 |
| A     | SD        |  0.72 |
| B     | Mean      |  2.81 |
| B     | Median    |     2 |
| B     | SD        |  1.33 |
]

A common cue to use `spread()` is having measurements of different quantities in the same column. 

---
# Before `spread()`

.smallish[
```{r}
(too_long_data <- data.frame(Group = c(rep("A", 3), rep("B", 3)),
                             Statistic = rep(c("Mean", "Median", "SD"), 2),
                             Value = c(1.28, 1.0, 0.72, 2.81, 2, 1.33)))
```
]

---
# After `spread()`

```{r}
(just_right_data <- too_long_data %>%
    spread(key = Statistic, value = Value))
```

---
# Charts of 2000: Data Prep

Let's look at songs that hit #1 at some point and look how they got there versus songs that did not:

```{r}
# find best rank for each song
best_rank <- billboard_2000 %>%
    group_by(artist, track) %>%
    summarize(min_rank = min(rank), #<<
              weeks_at_1 = sum(rank == 1)) %>%
    mutate(`Peak rank` = ifelse(min_rank == 1,
                                "Hit #1",
                                "Didn't #1"))

# merge onto original data
billboard_2000 <- billboard_2000 %>%
    left_join(best_rank, by = c("artist", "track"))
```

.footnote[Note that because the "highest" rank is *numerically lowest* (1), we are summarizing with `min()`.]

---
## Which Were #1 the Most Weeks?

```{r}
billboard_2000 %>%
    select(artist, track, weeks_at_1) %>%
    distinct(artist, track, weeks_at_1) %>%
    arrange(desc(weeks_at_1)) %>%
    head(7)
```

---
# Getting Usable Dates

We have the date the songs first charted, but not the dates for later weeks. We can calculate these now that the data are tidy:

```{r}
billboard_2000 <- billboard_2000 %>%
    mutate(date = date.entered + (week - 1) * 7) #<<
billboard_2000 %>% arrange(artist, track, week) %>%
    select(artist, date.entered, week, date, rank) %>% head(4)
```

This works because `date` objects are in units of days—we just add 7 days per week to the start date.

---
class: inverse
##Joining Data

---
## When Do We Need to Join Data?

* Want to make columns using criteria too complicated for `ifelse()` or `case_when()`

   * We can work with small sets of variables then combine them back together.

* Combine data stored in separate data sets: e.g. UW registrar information with police stop records.

   * Often large surveys are broken into different data sets for each level (e.g. household, individual, neighborhood)

---
## Joining in Concept

We need to think about the following when we want to merge data frames `A` and `B`:

* Which *rows* are we keeping from each data frame?

* Which *columns* are we keeping from each data frame?

* Which variables determine whether rows *match*?

---
## Join Types: Rows and columns kept

There are many types of joins<sup>1</sup>...

* `A %>% left_join(B)`: keep all rows from `A`, matched with `B` wherever possible (`NA` when not), keep columns from both `A` and `B`

* `A %>% right_join(B)`: keep all rows from `B`, matched with `A` wherever possible (`NA` when not), keep columns from both `A` and `B`

* `A %>% inner_join(B)`: keep only rows from `A` and `B` that match, keep columns from both `A` and `B`

* `A %>% full_join(B)`: keep all rows from both `A` and `B`, matched wherever possible (`NA` when not), keep columns from both `A` and `B`

* `A %>% semi_join(B)`: keep rows from `A` that match rows in `B`, keep columns from only `A`

* `A %>% anti_join(B)`: keep rows from `A` that *don't* match a row in `B`, keep columns from only `A`

.pull-right[.footnote[[1] Usually `left_join()` does the job.]]

---
## Matching Criteria

We say rows should *match* because they have some columns containing the same value. We list these in a `by = ` argument to the join.

Matching Behavior:

* No `by`: Match using all variables in `A` and `B` that have identical names

--

* `by = c("var1", "var2", "var3")`: Match on identical values of `var1`, `var2`, and `var3` in both `A` and `B`

--

* `by = c("Avar1" = "Bvar1", "Avar2" = "Bvar2")`: Match identical values of `Avar1` variable in `A` to `Bvar1` variable in `B`, and `Avar2` variable in `A` to `Bvar2` variable in `B`

Note: If there are multiple matches, you'll get *one row for each possible combination* (except with `semi_join()` and `anti_join()`).

Need to get more complicated? Break it into multiple operations.

---
## `nycflights13` Data

We'll use data in the [`nycflights13` package](https://cran.r-project.org/web/packages/nycflights13/nycflights13.pdf).

```{r}
library(nycflights13)
```

It includes five dataframes, some of which contain missing data (`NA`):

* `flights`: flights leaving JFK, LGA, or EWR in 2013
* `airlines`: airline abbreviations
* `airports`: airport metadata
* `planes`: airplane metadata
* `weather`: hourly weather data for JFK, LGA, and EWR

Note these are *separate data frames*, each needing to be *loaded separately*:

```{r, eval=FALSE}
data(flights)
data(airlines)
data(airports)
# and so on...
```

---
## Join Example

Who manufactures the planes that flew to SeaTac?

```{r}
flights %>% filter(dest == "SEA") %>% select(tailnum) %>%
    left_join(planes %>% select(tailnum, manufacturer), #<<
              by = "tailnum") %>%
    count(manufacturer) %>% # Count observations by manufacturer
    arrange(desc(n)) # Arrange data descending by count
```

Note you can perform operations on the data inside functions such as `left_join()` and the *output* will be used by the function.

---
# Visualization Preview

The next workshop will focus on visualization using `ggplot2`.

We could visualize the data we worked with today to understand it better.

---
# Charts of 2000: `ggplot2`

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
billboard_trajectories <- 
  ggplot(data = billboard_2000,
         aes(x = week, y = rank, group = track,
             color = `Peak rank`)
         ) +
  geom_line(aes(size = `Peak rank`), alpha = 0.4) +
    # rescale time: early weeks more important
  scale_x_log10(breaks = seq(0, 70, 10)) + 
  scale_y_reverse() + # want rank 1 on top, not bottom
  theme_classic() +
  xlab("Week") + ylab("Rank") +
  scale_color_manual("Peak Rank", values = c("black", "red")) +
  scale_size_manual("Peak Rank", values = c(0.25, 1)) +
  theme(legend.position = c(0.90, 0.25),
        legend.background = element_rect(fill="transparent"))
```

---
# Charts of 2000: Beauty!

```{r, cache=FALSE, echo=FALSE, dev="svg", fig.height=4}
billboard_trajectories
```

Observation: There appears to be censoring around week 20 for songs falling out of the top 50 that I'd want to follow up on.

---
# Resources

   * [UW CSSS508](https://clanfear.github.io/CSSS508/): My University of Washington Introduction to R course which forms the basis for this workshop. All content including lecture videos is freely available.
   * [R for Data Science](http://r4ds.had.co.nz/) online textbook by Garrett Grolemund and Hadley Wickham. One of many good R texts available, but importantly it is free and focuses on the [`tidyverse`](http://tidyverse.org/) collection of R packages which are the modern standard for data manipulation and visualization in R.
   * [Advanced R](http://adv-r.had.co.nz/) online textbook by Hadley Wickham. A great source for more in-depth and advanced R programming.
   * [DataCamp](https://www.datacamp.com/): A source for interactive R tutorials (some free of charge).
   * [`swirl`](http://swirlstats.com/students.html): Interactive tutorials inside R.
   * [Useful RStudio cheatsheets](https://www.rstudio.com/resources/cheatsheets/) on R Markdown, RStudio shortcuts, etc.
